Experiment: run_20260203_111242
================================================================================

CONFIGURATION:
--------------------------------------------------------------------------------
data: {'dataset_path': '/.automount/net_rw/net__data_ttk/soshaw', 'signal_file': '/.automount/net_rw/net__data_ttk/soshaw/sn_25k_SR_train.h5', 'background_file': '/.automount/net_rw/net__data_ttk/soshaw/bg_200k_SR_train.h5', 'n_jets_train': [25000, 200000], 'batch_size': 64, 'max_sequence_len': 128, 'mom4_format': 'epxpypz', 'train_val_split': 0.7, 'features': ['part_pt', 'part_etarel', 'part_phirel'], 'feature_preprocessing': {'part_pt': {'multiply_by': 1, 'subtract_by': 1.8, 'func': 'signed_log', 'inv_func': 'signed_exp'}, 'part_etarel': {'multiply_by': 3}, 'part_phirel': {'multiply_by': 3}}, 'shuffle_train': True, 'jet_name': 'both'}
model: {'architecture': 'BackboneDijetClassificationLightning', 'merge_strategy': 'attention', 'class_head_type': 'class_attention', 'use_continuous_input': True, 'num_parameters': 1903490, 'embedding_dim': 128, 'n_transformer_blocks': 2, 'num_attention_heads': 8, 'max_sequence_len': 128, 'n_output_classes': 2, 'model_kwargs': {'embedding_dim': 128, 'max_sequence_len': 128, 'n_out_nodes': 2, 'embed_cfg': {'type': 'continuous_project_add', 'intermediate_dim': None}, 'transformer_cfg': {'dim': 128, 'n_blocks': 8, 'norm_after_blocks': True, 'residual_cfg': {'gate_type': 'local', 'init_value': 1}, 'attn_cfg': {'num_heads': 8, 'dropout_rate': 0.1, 'norm_before': True, 'norm_after': False}, 'mlp_cfg': {'dropout_rate': 0.0, 'norm_before': True, 'expansion_factor': 4, 'activation': 'GELU'}}, 'class_head_hidden_dim': 128, 'class_head_num_heads': 8, 'class_head_num_CA_blocks': 2, 'class_head_num_SA_blocks': 0, 'class_head_dropout_rate': 0.1, 'jet_features_input_dim': 0, 'apply_causal_mask': False, 'zero_padded_start_particle': False, 'class_weights': [0.5625, 4.5]}}
training: {'optimizer': 'AdamW', 'optimizer_params': {'lr': 0.001, 'weight_decay': 0.01, 'partial': True}, 'scheduler': 'CosineAnnealingLR', 'scheduler_params': {'T_max': 1000000, 'eta_min': 1e-06}, 'max_steps': 1000000, 'gradient_clip_val': 1.0, 'precision': '32', 'early_stopping_patience': 15, 'early_stopping_monitor': 'val_loss', 'use_class_weights': True, 'class_weights': [0.5625, 4.5]}
system: {'device': 'cuda:0', 'gpu_id': 0, 'random_seed': 17, 'timestamp_start': '2026-02-03T11:43:48.079410'}

RESULTS:
--------------------------------------------------------------------------------
best_model_path: /.automount/home/home__home3/institut_thp/soshaw/AnomalyDetection/dijet_expts/run_20260203_111242/checkpoints/anomaly_detector_epoch=124_val_loss=0.0946.ckpt
best_model_score: 0.09458985179662704
current_epoch: 407
global_step: 1000000
training_completed: True
timestamp_end: 2026-02-04T12:57:51.459359
final_metrics: {'train_loss': 6.842582661192864e-05, 'train_loss_step': -0.0, 'train_acc': 0.9999812841415405, 'train_acc_step': 1.0, 'val_loss': 0.9325078725814819, 'val_loss_epoch': 0.9325078725814819, 'val_acc': 0.9800740480422974, 'val_acc_epoch': 0.9800740480422974, 'val_auc': 0.9887850284576416, 'train_loss_epoch': 6.842582661192864e-05, 'train_acc_epoch': 0.9999812841415405, 'epoch_train_duration_minutes': 0.9276957511901855}
